{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9RVmvnGAc8M"
   },
   "source": [
    "ECE 5460, Au23\n",
    "\n",
    "Solution for PyTorch Tutorial - final model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VTE_nLMo2fN_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "norm_mean = [0.485, 0.456, 0.406]  # mean\n",
    "norm_std = [0.229, 0.224, 0.225]  # std\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "ds = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "# spliting training into train and validation\n",
    "generator = torch.Generator().manual_seed(5460)\n",
    "(trainset, valset) = torch.utils.data.random_split(ds, [0.8, 0.2], generator=generator)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-B_apPu28ZU"
   },
   "source": [
    "We will use a convolutional network for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gExfCbTp2rpU"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x) # resnet design\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = Block(3, 64, stride=1)\n",
    "        self.layer2 = Block(64, 128, stride=2)\n",
    "        self.layer3 = Block(128, 256, stride=2)\n",
    "        self.layer4 = Block(256, 512, stride=2)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.layer5(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puswg-MZ3L-s"
   },
   "source": [
    "Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5SBwuTVE3OrD"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001) #Experiment with momentum term and other learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GeOz1Gh3QQT"
   },
   "source": [
    "Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kteVZXEm3czt"
   },
   "outputs": [],
   "source": [
    "def train_step(model, inputs, labels):\n",
    "  # zero the parameter gradients\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # forward call\n",
    "  outputs = model(inputs)\n",
    "\n",
    "  # calculate loss\n",
    "  loss = criterion(outputs, labels)\n",
    "\n",
    "  # back propagation and optimization\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_htmffPq4Cck"
   },
   "source": [
    "Define evaluation function\n",
    "\n",
    "Same can be used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mMw9wi2G4FAb"
   },
   "outputs": [],
   "source": [
    "def val_step(model, inputs, labels):\n",
    "  # get inputs and labels from given batch\n",
    "  with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # calculate the predicted class\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    loss = criterion(outputs, labels)\n",
    "    correct_pred = (predicted == labels).sum().item() # correctly classified samples of the current batch\n",
    "  return correct_pred, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVyYxxZd4vIz"
   },
   "source": [
    "Main training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bDLwIDDe4t4V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda:0\n",
      "epoch 0, step = 01000, running loss = 2.0938\n",
      "epoch 0, step = 02000, running loss = 1.9608\n",
      "epoch 0, step = 03000, running loss = 1.8704\n",
      "epoch 0, step = 04000, running loss = 1.8116\n",
      "epoch 0, step = 05000, running loss = 1.7753\n",
      "epoch 0, step = 06000, running loss = 1.7165\n",
      "epoch 0, step = 07000, running loss = 1.7120\n",
      "epoch 0, step = 08000, running loss = 1.6687\n",
      "epoch 0, step = 09000, running loss = 1.6436\n",
      "epoch 0, step = 10000, running loss = 1.6244\n",
      "val accuracy: 43.28, avg loss = 1.603\n",
      "epoch 1, step = 01000, running loss = 1.5641\n",
      "epoch 1, step = 02000, running loss = 1.5468\n",
      "epoch 1, step = 03000, running loss = 1.5386\n",
      "epoch 1, step = 04000, running loss = 1.5157\n",
      "epoch 1, step = 05000, running loss = 1.4859\n",
      "epoch 1, step = 06000, running loss = 1.4402\n",
      "epoch 1, step = 07000, running loss = 1.4514\n",
      "epoch 1, step = 08000, running loss = 1.4177\n",
      "epoch 1, step = 09000, running loss = 1.4128\n",
      "epoch 1, step = 10000, running loss = 1.3831\n",
      "val accuracy: 51.81, avg loss = 1.377\n",
      "epoch 2, step = 01000, running loss = 1.3512\n",
      "epoch 2, step = 02000, running loss = 1.3347\n",
      "epoch 2, step = 03000, running loss = 1.3479\n",
      "epoch 2, step = 04000, running loss = 1.2678\n",
      "epoch 2, step = 05000, running loss = 1.2530\n",
      "epoch 2, step = 06000, running loss = 1.2634\n",
      "epoch 2, step = 07000, running loss = 1.2668\n",
      "epoch 2, step = 08000, running loss = 1.2194\n",
      "epoch 2, step = 09000, running loss = 1.2196\n",
      "epoch 2, step = 10000, running loss = 1.1798\n",
      "val accuracy: 57.10, avg loss = 1.205\n",
      "epoch 3, step = 01000, running loss = 1.1905\n",
      "epoch 3, step = 02000, running loss = 1.1809\n",
      "epoch 3, step = 03000, running loss = 1.1388\n",
      "epoch 3, step = 04000, running loss = 1.1328\n",
      "epoch 3, step = 05000, running loss = 1.1224\n",
      "epoch 3, step = 06000, running loss = 1.1293\n",
      "epoch 3, step = 07000, running loss = 1.1033\n",
      "epoch 3, step = 08000, running loss = 1.0923\n",
      "epoch 3, step = 09000, running loss = 1.1246\n",
      "epoch 3, step = 10000, running loss = 1.0920\n",
      "val accuracy: 61.80, avg loss = 1.101\n",
      "epoch 4, step = 01000, running loss = 1.0632\n",
      "epoch 4, step = 02000, running loss = 1.0619\n",
      "epoch 4, step = 03000, running loss = 1.0337\n",
      "epoch 4, step = 04000, running loss = 1.0098\n",
      "epoch 4, step = 05000, running loss = 1.0546\n",
      "epoch 4, step = 06000, running loss = 1.0379\n",
      "epoch 4, step = 07000, running loss = 1.0156\n",
      "epoch 4, step = 08000, running loss = 1.0172\n",
      "epoch 4, step = 09000, running loss = 0.9979\n",
      "epoch 4, step = 10000, running loss = 0.9709\n",
      "val accuracy: 64.14, avg loss = 1.014\n",
      "epoch 5, step = 01000, running loss = 0.9813\n",
      "epoch 5, step = 02000, running loss = 0.9595\n",
      "epoch 5, step = 03000, running loss = 0.9358\n",
      "epoch 5, step = 04000, running loss = 0.9441\n",
      "epoch 5, step = 05000, running loss = 0.9294\n",
      "epoch 5, step = 06000, running loss = 0.9484\n",
      "epoch 5, step = 07000, running loss = 0.9184\n",
      "epoch 5, step = 08000, running loss = 0.9387\n",
      "epoch 5, step = 09000, running loss = 0.9136\n",
      "epoch 5, step = 10000, running loss = 0.9298\n",
      "val accuracy: 67.76, avg loss = 0.914\n",
      "epoch 6, step = 01000, running loss = 0.8716\n",
      "epoch 6, step = 02000, running loss = 0.9061\n",
      "epoch 6, step = 03000, running loss = 0.9007\n",
      "epoch 6, step = 04000, running loss = 0.8720\n",
      "epoch 6, step = 05000, running loss = 0.8502\n",
      "epoch 6, step = 06000, running loss = 0.8846\n",
      "epoch 6, step = 07000, running loss = 0.8342\n",
      "epoch 6, step = 08000, running loss = 0.8558\n",
      "epoch 6, step = 09000, running loss = 0.8217\n",
      "epoch 6, step = 10000, running loss = 0.8714\n",
      "val accuracy: 70.95, avg loss = 0.845\n",
      "epoch 7, step = 01000, running loss = 0.8541\n",
      "epoch 7, step = 02000, running loss = 0.8058\n",
      "epoch 7, step = 03000, running loss = 0.8034\n",
      "epoch 7, step = 04000, running loss = 0.8283\n",
      "epoch 7, step = 05000, running loss = 0.7890\n",
      "epoch 7, step = 06000, running loss = 0.7989\n",
      "epoch 7, step = 07000, running loss = 0.7914\n",
      "epoch 7, step = 08000, running loss = 0.7971\n",
      "epoch 7, step = 09000, running loss = 0.7950\n",
      "epoch 7, step = 10000, running loss = 0.7639\n",
      "val accuracy: 71.52, avg loss = 0.826\n",
      "epoch 8, step = 01000, running loss = 0.7553\n",
      "epoch 8, step = 02000, running loss = 0.7536\n",
      "epoch 8, step = 03000, running loss = 0.7627\n",
      "epoch 8, step = 04000, running loss = 0.7542\n",
      "epoch 8, step = 05000, running loss = 0.7545\n",
      "epoch 8, step = 06000, running loss = 0.7637\n",
      "epoch 8, step = 07000, running loss = 0.7619\n",
      "epoch 8, step = 08000, running loss = 0.7326\n",
      "epoch 8, step = 09000, running loss = 0.7343\n",
      "epoch 8, step = 10000, running loss = 0.7468\n",
      "val accuracy: 74.48, avg loss = 0.750\n",
      "epoch 9, step = 01000, running loss = 0.7256\n",
      "epoch 9, step = 02000, running loss = 0.7393\n",
      "epoch 9, step = 03000, running loss = 0.6744\n",
      "epoch 9, step = 04000, running loss = 0.7105\n",
      "epoch 9, step = 05000, running loss = 0.7008\n",
      "epoch 9, step = 06000, running loss = 0.7050\n",
      "epoch 9, step = 07000, running loss = 0.7377\n",
      "epoch 9, step = 08000, running loss = 0.6955\n",
      "epoch 9, step = 09000, running loss = 0.6701\n",
      "epoch 9, step = 10000, running loss = 0.7207\n",
      "val accuracy: 73.77, avg loss = 0.753\n",
      "epoch 10, step = 01000, running loss = 0.6719\n",
      "epoch 10, step = 02000, running loss = 0.6519\n",
      "epoch 10, step = 03000, running loss = 0.6655\n",
      "epoch 10, step = 04000, running loss = 0.6800\n",
      "epoch 10, step = 05000, running loss = 0.7272\n",
      "epoch 10, step = 06000, running loss = 0.6712\n",
      "epoch 10, step = 07000, running loss = 0.6498\n",
      "epoch 10, step = 08000, running loss = 0.6780\n",
      "epoch 10, step = 09000, running loss = 0.6521\n",
      "epoch 10, step = 10000, running loss = 0.6635\n",
      "val accuracy: 75.94, avg loss = 0.689\n",
      "epoch 11, step = 01000, running loss = 0.6384\n",
      "epoch 11, step = 02000, running loss = 0.6300\n",
      "epoch 11, step = 03000, running loss = 0.6218\n",
      "epoch 11, step = 04000, running loss = 0.6541\n",
      "epoch 11, step = 05000, running loss = 0.6355\n",
      "epoch 11, step = 06000, running loss = 0.6054\n",
      "epoch 11, step = 07000, running loss = 0.6370\n",
      "epoch 11, step = 08000, running loss = 0.6393\n",
      "epoch 11, step = 09000, running loss = 0.6611\n",
      "epoch 11, step = 10000, running loss = 0.6412\n",
      "val accuracy: 77.68, avg loss = 0.657\n",
      "epoch 12, step = 01000, running loss = 0.6209\n",
      "epoch 12, step = 02000, running loss = 0.5923\n",
      "epoch 12, step = 03000, running loss = 0.6165\n",
      "epoch 12, step = 04000, running loss = 0.6034\n",
      "epoch 12, step = 05000, running loss = 0.6292\n",
      "epoch 12, step = 06000, running loss = 0.6032\n",
      "epoch 12, step = 07000, running loss = 0.6060\n",
      "epoch 12, step = 08000, running loss = 0.5947\n",
      "epoch 12, step = 09000, running loss = 0.6114\n",
      "epoch 12, step = 10000, running loss = 0.6126\n",
      "val accuracy: 78.14, avg loss = 0.642\n",
      "epoch 13, step = 01000, running loss = 0.6007\n",
      "epoch 13, step = 02000, running loss = 0.5787\n",
      "epoch 13, step = 03000, running loss = 0.5947\n",
      "epoch 13, step = 04000, running loss = 0.5876\n",
      "epoch 13, step = 05000, running loss = 0.5823\n",
      "epoch 13, step = 06000, running loss = 0.5786\n",
      "epoch 13, step = 07000, running loss = 0.5635\n",
      "epoch 13, step = 08000, running loss = 0.5768\n",
      "epoch 13, step = 09000, running loss = 0.5952\n",
      "epoch 13, step = 10000, running loss = 0.5638\n",
      "val accuracy: 79.15, avg loss = 0.606\n",
      "epoch 14, step = 01000, running loss = 0.5666\n",
      "epoch 14, step = 02000, running loss = 0.5414\n",
      "epoch 14, step = 03000, running loss = 0.5727\n",
      "epoch 14, step = 04000, running loss = 0.5505\n",
      "epoch 14, step = 05000, running loss = 0.5798\n",
      "epoch 14, step = 06000, running loss = 0.5542\n",
      "epoch 14, step = 07000, running loss = 0.5628\n",
      "epoch 14, step = 08000, running loss = 0.5428\n",
      "epoch 14, step = 09000, running loss = 0.5482\n",
      "epoch 14, step = 10000, running loss = 0.5491\n",
      "val accuracy: 79.90, avg loss = 0.595\n",
      "epoch 15, step = 01000, running loss = 0.5230\n",
      "epoch 15, step = 02000, running loss = 0.5294\n",
      "epoch 15, step = 03000, running loss = 0.5410\n",
      "epoch 15, step = 04000, running loss = 0.5071\n",
      "epoch 15, step = 05000, running loss = 0.5426\n",
      "epoch 15, step = 06000, running loss = 0.5496\n",
      "epoch 15, step = 07000, running loss = 0.5458\n",
      "epoch 15, step = 08000, running loss = 0.5715\n",
      "epoch 15, step = 09000, running loss = 0.5221\n",
      "epoch 15, step = 10000, running loss = 0.5302\n",
      "val accuracy: 80.05, avg loss = 0.582\n",
      "epoch 16, step = 01000, running loss = 0.5210\n",
      "epoch 16, step = 02000, running loss = 0.5152\n",
      "epoch 16, step = 03000, running loss = 0.5075\n",
      "epoch 16, step = 04000, running loss = 0.5224\n",
      "epoch 16, step = 05000, running loss = 0.5327\n",
      "epoch 16, step = 06000, running loss = 0.4936\n",
      "epoch 16, step = 07000, running loss = 0.4965\n",
      "epoch 16, step = 08000, running loss = 0.5218\n",
      "epoch 16, step = 09000, running loss = 0.4947\n",
      "epoch 16, step = 10000, running loss = 0.4969\n",
      "val accuracy: 80.18, avg loss = 0.578\n",
      "epoch 17, step = 01000, running loss = 0.5161\n",
      "epoch 17, step = 02000, running loss = 0.5108\n",
      "epoch 17, step = 03000, running loss = 0.5087\n",
      "epoch 17, step = 04000, running loss = 0.4894\n",
      "epoch 17, step = 05000, running loss = 0.5139\n",
      "epoch 17, step = 06000, running loss = 0.4829\n",
      "epoch 17, step = 07000, running loss = 0.5008\n",
      "epoch 17, step = 08000, running loss = 0.4744\n",
      "epoch 17, step = 09000, running loss = 0.4968\n",
      "epoch 17, step = 10000, running loss = 0.4875\n",
      "val accuracy: 80.89, avg loss = 0.552\n",
      "epoch 18, step = 01000, running loss = 0.4880\n",
      "epoch 18, step = 02000, running loss = 0.4645\n",
      "epoch 18, step = 03000, running loss = 0.4823\n",
      "epoch 18, step = 04000, running loss = 0.5075\n",
      "epoch 18, step = 05000, running loss = 0.4914\n",
      "epoch 18, step = 06000, running loss = 0.4492\n",
      "epoch 18, step = 07000, running loss = 0.4993\n",
      "epoch 18, step = 08000, running loss = 0.4584\n",
      "epoch 18, step = 09000, running loss = 0.4766\n",
      "epoch 18, step = 10000, running loss = 0.4632\n",
      "val accuracy: 81.89, avg loss = 0.530\n",
      "epoch 19, step = 01000, running loss = 0.4720\n",
      "epoch 19, step = 02000, running loss = 0.4672\n",
      "epoch 19, step = 03000, running loss = 0.4627\n",
      "epoch 19, step = 04000, running loss = 0.4458\n",
      "epoch 19, step = 05000, running loss = 0.4470\n",
      "epoch 19, step = 06000, running loss = 0.4562\n",
      "epoch 19, step = 07000, running loss = 0.4577\n",
      "epoch 19, step = 08000, running loss = 0.4837\n",
      "epoch 19, step = 09000, running loss = 0.4836\n",
      "epoch 19, step = 10000, running loss = 0.4519\n",
      "val accuracy: 81.97, avg loss = 0.524\n",
      "epoch 20, step = 01000, running loss = 0.4504\n",
      "epoch 20, step = 02000, running loss = 0.4470\n",
      "epoch 20, step = 03000, running loss = 0.4408\n",
      "epoch 20, step = 04000, running loss = 0.4498\n",
      "epoch 20, step = 05000, running loss = 0.4396\n",
      "epoch 20, step = 06000, running loss = 0.4624\n",
      "epoch 20, step = 07000, running loss = 0.4603\n",
      "epoch 20, step = 08000, running loss = 0.4505\n",
      "epoch 20, step = 09000, running loss = 0.4560\n",
      "epoch 20, step = 10000, running loss = 0.4587\n",
      "val accuracy: 82.22, avg loss = 0.520\n",
      "epoch 21, step = 01000, running loss = 0.4279\n",
      "epoch 21, step = 02000, running loss = 0.4564\n",
      "epoch 21, step = 03000, running loss = 0.4580\n",
      "epoch 21, step = 04000, running loss = 0.4369\n",
      "epoch 21, step = 05000, running loss = 0.4202\n",
      "epoch 21, step = 06000, running loss = 0.4261\n",
      "epoch 21, step = 07000, running loss = 0.4312\n",
      "epoch 21, step = 08000, running loss = 0.4549\n",
      "epoch 21, step = 09000, running loss = 0.4397\n",
      "epoch 21, step = 10000, running loss = 0.4381\n",
      "val accuracy: 82.88, avg loss = 0.505\n",
      "epoch 22, step = 01000, running loss = 0.4295\n",
      "epoch 22, step = 02000, running loss = 0.4280\n",
      "epoch 22, step = 03000, running loss = 0.4160\n",
      "epoch 22, step = 04000, running loss = 0.4256\n",
      "epoch 22, step = 05000, running loss = 0.4076\n",
      "epoch 22, step = 06000, running loss = 0.4344\n",
      "epoch 22, step = 07000, running loss = 0.4324\n",
      "epoch 22, step = 08000, running loss = 0.4426\n",
      "epoch 22, step = 09000, running loss = 0.3966\n",
      "epoch 22, step = 10000, running loss = 0.4277\n",
      "val accuracy: 82.76, avg loss = 0.511\n",
      "epoch 23, step = 01000, running loss = 0.4197\n",
      "epoch 23, step = 02000, running loss = 0.3962\n",
      "epoch 23, step = 03000, running loss = 0.4071\n",
      "epoch 23, step = 04000, running loss = 0.3877\n",
      "epoch 23, step = 05000, running loss = 0.4170\n",
      "epoch 23, step = 06000, running loss = 0.4399\n",
      "epoch 23, step = 07000, running loss = 0.3991\n",
      "epoch 23, step = 08000, running loss = 0.4297\n",
      "epoch 23, step = 09000, running loss = 0.4162\n",
      "epoch 23, step = 10000, running loss = 0.3989\n",
      "val accuracy: 83.49, avg loss = 0.480\n",
      "epoch 24, step = 01000, running loss = 0.4000\n",
      "epoch 24, step = 02000, running loss = 0.3933\n",
      "epoch 24, step = 03000, running loss = 0.4116\n",
      "epoch 24, step = 04000, running loss = 0.4076\n",
      "epoch 24, step = 05000, running loss = 0.3951\n",
      "epoch 24, step = 06000, running loss = 0.3724\n",
      "epoch 24, step = 07000, running loss = 0.4059\n",
      "epoch 24, step = 08000, running loss = 0.4038\n",
      "epoch 24, step = 09000, running loss = 0.4001\n",
      "epoch 24, step = 10000, running loss = 0.3960\n",
      "val accuracy: 83.49, avg loss = 0.487\n",
      "epoch 25, step = 01000, running loss = 0.3881\n",
      "epoch 25, step = 02000, running loss = 0.3877\n",
      "epoch 25, step = 03000, running loss = 0.3937\n",
      "epoch 25, step = 04000, running loss = 0.3854\n",
      "epoch 25, step = 05000, running loss = 0.3966\n",
      "epoch 25, step = 06000, running loss = 0.3962\n",
      "epoch 25, step = 07000, running loss = 0.4079\n",
      "epoch 25, step = 08000, running loss = 0.3994\n",
      "epoch 25, step = 09000, running loss = 0.3617\n",
      "epoch 25, step = 10000, running loss = 0.3809\n",
      "val accuracy: 84.02, avg loss = 0.465\n",
      "epoch 26, step = 01000, running loss = 0.3738\n",
      "epoch 26, step = 02000, running loss = 0.3536\n",
      "epoch 26, step = 03000, running loss = 0.3651\n",
      "epoch 26, step = 04000, running loss = 0.3704\n",
      "epoch 26, step = 05000, running loss = 0.3739\n",
      "epoch 26, step = 06000, running loss = 0.4172\n",
      "epoch 26, step = 07000, running loss = 0.3765\n",
      "epoch 26, step = 08000, running loss = 0.3862\n",
      "epoch 26, step = 09000, running loss = 0.3850\n",
      "epoch 26, step = 10000, running loss = 0.3643\n",
      "val accuracy: 83.28, avg loss = 0.493\n",
      "epoch 27, step = 01000, running loss = 0.3576\n",
      "epoch 27, step = 02000, running loss = 0.3718\n",
      "epoch 27, step = 03000, running loss = 0.3570\n",
      "epoch 27, step = 04000, running loss = 0.3604\n",
      "epoch 27, step = 05000, running loss = 0.3531\n",
      "epoch 27, step = 06000, running loss = 0.3672\n",
      "epoch 27, step = 07000, running loss = 0.3898\n",
      "epoch 27, step = 08000, running loss = 0.3743\n",
      "epoch 27, step = 09000, running loss = 0.3812\n",
      "epoch 27, step = 10000, running loss = 0.3535\n",
      "val accuracy: 84.53, avg loss = 0.452\n",
      "epoch 28, step = 01000, running loss = 0.3426\n",
      "epoch 28, step = 02000, running loss = 0.3472\n",
      "epoch 28, step = 03000, running loss = 0.3433\n",
      "epoch 28, step = 04000, running loss = 0.3657\n",
      "epoch 28, step = 05000, running loss = 0.3795\n",
      "epoch 28, step = 06000, running loss = 0.3646\n",
      "epoch 28, step = 07000, running loss = 0.3633\n",
      "epoch 28, step = 08000, running loss = 0.3601\n",
      "epoch 28, step = 09000, running loss = 0.3564\n",
      "epoch 28, step = 10000, running loss = 0.3411\n",
      "val accuracy: 85.07, avg loss = 0.441\n",
      "epoch 29, step = 01000, running loss = 0.3406\n",
      "epoch 29, step = 02000, running loss = 0.3482\n",
      "epoch 29, step = 03000, running loss = 0.3483\n",
      "epoch 29, step = 04000, running loss = 0.3568\n",
      "epoch 29, step = 05000, running loss = 0.3414\n",
      "epoch 29, step = 06000, running loss = 0.3565\n",
      "epoch 29, step = 07000, running loss = 0.3495\n",
      "epoch 29, step = 08000, running loss = 0.3524\n",
      "epoch 29, step = 09000, running loss = 0.3279\n",
      "epoch 29, step = 10000, running loss = 0.3319\n",
      "val accuracy: 84.76, avg loss = 0.436\n",
      "epoch 30, step = 01000, running loss = 0.3475\n",
      "epoch 30, step = 02000, running loss = 0.3241\n",
      "epoch 30, step = 03000, running loss = 0.3413\n",
      "epoch 30, step = 04000, running loss = 0.3167\n",
      "epoch 30, step = 05000, running loss = 0.3277\n",
      "epoch 30, step = 06000, running loss = 0.3334\n",
      "epoch 30, step = 07000, running loss = 0.3276\n",
      "epoch 30, step = 08000, running loss = 0.3545\n",
      "epoch 30, step = 09000, running loss = 0.3421\n",
      "epoch 30, step = 10000, running loss = 0.3529\n",
      "val accuracy: 84.98, avg loss = 0.443\n",
      "epoch 31, step = 01000, running loss = 0.3263\n",
      "epoch 31, step = 02000, running loss = 0.3377\n",
      "epoch 31, step = 03000, running loss = 0.3395\n",
      "epoch 31, step = 04000, running loss = 0.3327\n",
      "epoch 31, step = 05000, running loss = 0.3413\n",
      "epoch 31, step = 06000, running loss = 0.3348\n",
      "epoch 31, step = 07000, running loss = 0.3178\n",
      "epoch 31, step = 08000, running loss = 0.3215\n",
      "epoch 31, step = 09000, running loss = 0.3314\n",
      "epoch 31, step = 10000, running loss = 0.3251\n",
      "val accuracy: 84.99, avg loss = 0.434\n",
      "epoch 32, step = 01000, running loss = 0.3171\n",
      "epoch 32, step = 02000, running loss = 0.3015\n",
      "epoch 32, step = 03000, running loss = 0.3175\n",
      "epoch 32, step = 04000, running loss = 0.3036\n",
      "epoch 32, step = 05000, running loss = 0.3427\n",
      "epoch 32, step = 06000, running loss = 0.3137\n",
      "epoch 32, step = 07000, running loss = 0.3107\n",
      "epoch 32, step = 08000, running loss = 0.3384\n",
      "epoch 32, step = 09000, running loss = 0.3201\n",
      "epoch 32, step = 10000, running loss = 0.3197\n",
      "val accuracy: 85.14, avg loss = 0.435\n",
      "epoch 33, step = 01000, running loss = 0.3123\n",
      "epoch 33, step = 02000, running loss = 0.3128\n",
      "epoch 33, step = 03000, running loss = 0.3092\n",
      "epoch 33, step = 04000, running loss = 0.3122\n",
      "epoch 33, step = 05000, running loss = 0.3288\n",
      "epoch 33, step = 06000, running loss = 0.3110\n",
      "epoch 33, step = 07000, running loss = 0.2998\n",
      "epoch 33, step = 08000, running loss = 0.2981\n",
      "epoch 33, step = 09000, running loss = 0.2974\n",
      "epoch 33, step = 10000, running loss = 0.3110\n",
      "val accuracy: 85.90, avg loss = 0.424\n",
      "epoch 34, step = 01000, running loss = 0.2838\n",
      "epoch 34, step = 02000, running loss = 0.3016\n",
      "epoch 34, step = 03000, running loss = 0.3009\n",
      "epoch 34, step = 04000, running loss = 0.3125\n",
      "epoch 34, step = 05000, running loss = 0.2912\n",
      "epoch 34, step = 06000, running loss = 0.3047\n",
      "epoch 34, step = 07000, running loss = 0.3123\n",
      "epoch 34, step = 08000, running loss = 0.3187\n",
      "epoch 34, step = 09000, running loss = 0.3332\n",
      "epoch 34, step = 10000, running loss = 0.3040\n",
      "val accuracy: 85.83, avg loss = 0.414\n",
      "epoch 35, step = 01000, running loss = 0.3005\n",
      "epoch 35, step = 02000, running loss = 0.3182\n",
      "epoch 35, step = 03000, running loss = 0.3000\n",
      "epoch 35, step = 04000, running loss = 0.2855\n",
      "epoch 35, step = 05000, running loss = 0.2878\n",
      "epoch 35, step = 06000, running loss = 0.3000\n",
      "epoch 35, step = 07000, running loss = 0.2905\n",
      "epoch 35, step = 08000, running loss = 0.3023\n",
      "epoch 35, step = 09000, running loss = 0.2981\n",
      "epoch 35, step = 10000, running loss = 0.3089\n",
      "val accuracy: 85.27, avg loss = 0.426\n",
      "epoch 36, step = 01000, running loss = 0.3020\n",
      "epoch 36, step = 02000, running loss = 0.2714\n",
      "epoch 36, step = 03000, running loss = 0.2820\n",
      "epoch 36, step = 04000, running loss = 0.2822\n",
      "epoch 36, step = 05000, running loss = 0.2857\n",
      "epoch 36, step = 06000, running loss = 0.2871\n",
      "epoch 36, step = 07000, running loss = 0.2758\n",
      "epoch 36, step = 08000, running loss = 0.2593\n",
      "epoch 36, step = 09000, running loss = 0.2931\n",
      "epoch 36, step = 10000, running loss = 0.2996\n",
      "val accuracy: 85.19, avg loss = 0.429\n",
      "epoch 37, step = 01000, running loss = 0.2879\n",
      "epoch 37, step = 02000, running loss = 0.2685\n",
      "epoch 37, step = 03000, running loss = 0.2671\n",
      "epoch 37, step = 04000, running loss = 0.2880\n",
      "epoch 37, step = 05000, running loss = 0.2681\n",
      "epoch 37, step = 06000, running loss = 0.2809\n",
      "epoch 37, step = 07000, running loss = 0.2986\n",
      "epoch 37, step = 08000, running loss = 0.2678\n",
      "epoch 37, step = 09000, running loss = 0.2819\n",
      "epoch 37, step = 10000, running loss = 0.2723\n",
      "val accuracy: 85.60, avg loss = 0.425\n",
      "epoch 38, step = 01000, running loss = 0.2629\n",
      "epoch 38, step = 02000, running loss = 0.2732\n",
      "epoch 38, step = 03000, running loss = 0.2757\n",
      "epoch 38, step = 04000, running loss = 0.2755\n",
      "epoch 38, step = 05000, running loss = 0.2851\n",
      "epoch 38, step = 06000, running loss = 0.2617\n",
      "epoch 38, step = 07000, running loss = 0.3008\n",
      "epoch 38, step = 08000, running loss = 0.2823\n",
      "epoch 38, step = 09000, running loss = 0.2790\n",
      "epoch 38, step = 10000, running loss = 0.2738\n",
      "val accuracy: 86.34, avg loss = 0.407\n",
      "epoch 39, step = 01000, running loss = 0.2529\n",
      "epoch 39, step = 02000, running loss = 0.2568\n",
      "epoch 39, step = 03000, running loss = 0.2501\n",
      "epoch 39, step = 04000, running loss = 0.2635\n",
      "epoch 39, step = 05000, running loss = 0.2823\n",
      "epoch 39, step = 06000, running loss = 0.2674\n",
      "epoch 39, step = 07000, running loss = 0.2689\n",
      "epoch 39, step = 08000, running loss = 0.2837\n",
      "epoch 39, step = 09000, running loss = 0.2844\n",
      "epoch 39, step = 10000, running loss = 0.2808\n",
      "val accuracy: 86.66, avg loss = 0.401\n",
      "epoch 40, step = 01000, running loss = 0.2367\n",
      "epoch 40, step = 02000, running loss = 0.2681\n",
      "epoch 40, step = 03000, running loss = 0.2578\n",
      "epoch 40, step = 04000, running loss = 0.2589\n",
      "epoch 40, step = 05000, running loss = 0.2503\n",
      "epoch 40, step = 06000, running loss = 0.2798\n",
      "epoch 40, step = 07000, running loss = 0.2557\n",
      "epoch 40, step = 08000, running loss = 0.2725\n",
      "epoch 40, step = 09000, running loss = 0.2572\n",
      "epoch 40, step = 10000, running loss = 0.2619\n",
      "val accuracy: 86.75, avg loss = 0.390\n",
      "epoch 41, step = 01000, running loss = 0.2483\n",
      "epoch 41, step = 02000, running loss = 0.2493\n",
      "epoch 41, step = 03000, running loss = 0.2497\n",
      "epoch 41, step = 04000, running loss = 0.2727\n",
      "epoch 41, step = 05000, running loss = 0.2607\n",
      "epoch 41, step = 06000, running loss = 0.2519\n",
      "epoch 41, step = 07000, running loss = 0.2636\n",
      "epoch 41, step = 08000, running loss = 0.2549\n",
      "epoch 41, step = 09000, running loss = 0.2508\n",
      "epoch 41, step = 10000, running loss = 0.2516\n",
      "val accuracy: 86.65, avg loss = 0.398\n",
      "epoch 42, step = 01000, running loss = 0.2321\n",
      "epoch 42, step = 02000, running loss = 0.2445\n",
      "epoch 42, step = 03000, running loss = 0.2507\n",
      "epoch 42, step = 04000, running loss = 0.2194\n",
      "epoch 42, step = 05000, running loss = 0.2377\n",
      "epoch 42, step = 06000, running loss = 0.2569\n",
      "epoch 42, step = 07000, running loss = 0.2622\n",
      "epoch 42, step = 08000, running loss = 0.2654\n",
      "epoch 42, step = 09000, running loss = 0.2625\n",
      "epoch 42, step = 10000, running loss = 0.2648\n",
      "val accuracy: 86.43, avg loss = 0.403\n",
      "epoch 43, step = 01000, running loss = 0.2347\n",
      "epoch 43, step = 02000, running loss = 0.2446\n",
      "epoch 43, step = 03000, running loss = 0.2400\n",
      "epoch 43, step = 04000, running loss = 0.2425\n",
      "epoch 43, step = 05000, running loss = 0.2393\n",
      "epoch 43, step = 06000, running loss = 0.2516\n",
      "epoch 43, step = 07000, running loss = 0.2422\n",
      "epoch 43, step = 08000, running loss = 0.2425\n",
      "epoch 43, step = 09000, running loss = 0.2658\n",
      "epoch 43, step = 10000, running loss = 0.2540\n",
      "val accuracy: 87.10, avg loss = 0.383\n",
      "epoch 44, step = 01000, running loss = 0.2266\n",
      "epoch 44, step = 02000, running loss = 0.2181\n",
      "epoch 44, step = 03000, running loss = 0.2313\n",
      "epoch 44, step = 04000, running loss = 0.2315\n",
      "epoch 44, step = 05000, running loss = 0.2509\n",
      "epoch 44, step = 06000, running loss = 0.2404\n",
      "epoch 44, step = 07000, running loss = 0.2379\n",
      "epoch 44, step = 08000, running loss = 0.2406\n",
      "epoch 44, step = 09000, running loss = 0.2390\n",
      "epoch 44, step = 10000, running loss = 0.2463\n",
      "val accuracy: 86.41, avg loss = 0.398\n",
      "epoch 45, step = 01000, running loss = 0.2271\n",
      "epoch 45, step = 02000, running loss = 0.2382\n",
      "epoch 45, step = 03000, running loss = 0.2324\n",
      "epoch 45, step = 04000, running loss = 0.2275\n",
      "epoch 45, step = 05000, running loss = 0.2246\n",
      "epoch 45, step = 06000, running loss = 0.2177\n",
      "epoch 45, step = 07000, running loss = 0.2349\n",
      "epoch 45, step = 08000, running loss = 0.2306\n",
      "epoch 45, step = 09000, running loss = 0.2491\n",
      "epoch 45, step = 10000, running loss = 0.2434\n",
      "val accuracy: 86.41, avg loss = 0.400\n",
      "epoch 46, step = 01000, running loss = 0.2100\n",
      "epoch 46, step = 02000, running loss = 0.2276\n",
      "epoch 46, step = 03000, running loss = 0.2437\n",
      "epoch 46, step = 04000, running loss = 0.2481\n",
      "epoch 46, step = 05000, running loss = 0.2417\n",
      "epoch 46, step = 06000, running loss = 0.2125\n",
      "epoch 46, step = 07000, running loss = 0.2252\n",
      "epoch 46, step = 08000, running loss = 0.2223\n",
      "epoch 46, step = 09000, running loss = 0.2266\n",
      "epoch 46, step = 10000, running loss = 0.2359\n",
      "val accuracy: 87.10, avg loss = 0.380\n",
      "epoch 47, step = 01000, running loss = 0.2076\n",
      "epoch 47, step = 02000, running loss = 0.2306\n",
      "epoch 47, step = 03000, running loss = 0.2327\n",
      "epoch 47, step = 04000, running loss = 0.2150\n",
      "epoch 47, step = 05000, running loss = 0.2334\n",
      "epoch 47, step = 06000, running loss = 0.2082\n",
      "epoch 47, step = 07000, running loss = 0.2143\n",
      "epoch 47, step = 08000, running loss = 0.2151\n",
      "epoch 47, step = 09000, running loss = 0.2256\n",
      "epoch 47, step = 10000, running loss = 0.2131\n",
      "val accuracy: 87.21, avg loss = 0.384\n",
      "epoch 48, step = 01000, running loss = 0.2034\n",
      "epoch 48, step = 02000, running loss = 0.2179\n",
      "epoch 48, step = 03000, running loss = 0.2123\n",
      "epoch 48, step = 04000, running loss = 0.2143\n",
      "epoch 48, step = 05000, running loss = 0.2042\n",
      "epoch 48, step = 06000, running loss = 0.2256\n",
      "epoch 48, step = 07000, running loss = 0.2101\n",
      "epoch 48, step = 08000, running loss = 0.2130\n",
      "epoch 48, step = 09000, running loss = 0.2292\n",
      "epoch 48, step = 10000, running loss = 0.2285\n",
      "val accuracy: 86.97, avg loss = 0.397\n",
      "epoch 49, step = 01000, running loss = 0.1989\n",
      "epoch 49, step = 02000, running loss = 0.2090\n",
      "epoch 49, step = 03000, running loss = 0.2047\n",
      "epoch 49, step = 04000, running loss = 0.1979\n",
      "epoch 49, step = 05000, running loss = 0.2244\n",
      "epoch 49, step = 06000, running loss = 0.2129\n",
      "epoch 49, step = 07000, running loss = 0.2039\n",
      "epoch 49, step = 08000, running loss = 0.2148\n",
      "epoch 49, step = 09000, running loss = 0.2148\n",
      "epoch 49, step = 10000, running loss = 0.2294\n",
      "val accuracy: 86.87, avg loss = 0.401\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 50 # change this to a larger number to train the final network\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using device: \", device)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "  running_loss = 0\n",
    "  for j, batch in enumerate(trainloader):\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # training step\n",
    "    loss = train_step(model, inputs, labels)\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # print some statistics\n",
    "    if (j+1) % 1000 == 0 :\n",
    "      print(\"epoch {}, step = {}, running loss = {:.4f}\".format(i, str(j+1).zfill(5), running_loss / 1000))\n",
    "      running_loss = 0\n",
    "\n",
    "\n",
    "\n",
    "  # validation at the end of each epoch\n",
    "  total_correct_pred = 0\n",
    "  val_loss = []\n",
    "  for _, batch in enumerate(valloader):\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    curr_correct_pred, curr_loss = val_step(model, inputs, labels)\n",
    "\n",
    "    # keep track of corrected samples and loss\n",
    "    total_correct_pred += curr_correct_pred\n",
    "    val_loss.append(curr_loss.item())\n",
    "\n",
    "  val_loss = torch.Tensor(val_loss).mean()\n",
    "  acc = total_correct_pred / len(valset)\n",
    "  print(\"val accuracy: {:.2f}, avg loss = {:.3f}\".format(100*acc, val_loss))\n",
    "  val_acc_log.append(acc * 100)\n",
    "  val_loss_log.append(val_loss.item())\n",
    "\n",
    "  # save the checkpoint\n",
    "  torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'epoch_{}_val_acc_{}.pt'.format(i, 100*acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NcV8B83ab6Tk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(val_loss_log)\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_ylabel('loss')\n",
    "ax[0].set_title('validation loss')\n",
    "\n",
    "\n",
    "ax[1].plot(val_acc_log)\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_ylabel('accuracy')\n",
    "ax[1].set_title('validation accuracy')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aomKGsVO7XY2"
   },
   "source": [
    "Testing\n",
    "\n",
    "The other things to do is to calculate the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) to see the accuracy of individual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SwB2EmvW7Yty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 83.48%\n"
     ]
    }
   ],
   "source": [
    "from os import access\n",
    "total_correct_pred = 0\n",
    "\n",
    "for i, batch in enumerate(testloader):\n",
    "  inputs, labels = batch\n",
    "  inputs = inputs.to(device)\n",
    "  labels = labels.to(device)\n",
    "\n",
    "  curr_correct_pred, _ = val_step(model, inputs, labels)\n",
    "\n",
    "  # adding up correctly predicted samples\n",
    "  total_correct_pred += curr_correct_pred\n",
    "\n",
    "# total accuracy\n",
    "acc = total_correct_pred / len(testloader.dataset)\n",
    "print(\"testing accuracy: {:.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

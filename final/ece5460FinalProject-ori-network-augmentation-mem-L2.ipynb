{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9RVmvnGAc8M"
   },
   "source": [
    "ECE 5460, Au23\n",
    "\n",
    "Solution for PyTorch Tutorial - final model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VTE_nLMo2fN_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "norm_mean = [0.485, 0.456, 0.406]  # mean\n",
    "norm_std = [0.229, 0.224, 0.225]  # std\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "ds = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "# spliting training into train and validation\n",
    "generator = torch.Generator().manual_seed(5460)\n",
    "(trainset, valset) = torch.utils.data.random_split(ds, [0.8, 0.2], generator=generator)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-B_apPu28ZU"
   },
   "source": [
    "We will use a convolutional network for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gExfCbTp2rpU"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x) # resnet design\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = Block(3, 64, stride=1)\n",
    "        self.layer2 = Block(64, 128, stride=2)\n",
    "        self.layer3 = Block(128, 256, stride=2)\n",
    "        self.layer4 = Block(256, 512, stride=2)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.layer5(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puswg-MZ3L-s"
   },
   "source": [
    "Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5SBwuTVE3OrD"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 50\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay) #Experiment with momentum term and other learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GeOz1Gh3QQT"
   },
   "source": [
    "Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kteVZXEm3czt"
   },
   "outputs": [],
   "source": [
    "def train_step(model, inputs, labels):\n",
    "  # zero the parameter gradients\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # forward call\n",
    "  outputs = model(inputs)\n",
    "\n",
    "  # calculate loss\n",
    "  loss = criterion(outputs, labels)\n",
    "\n",
    "  # back propagation and optimization\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_htmffPq4Cck"
   },
   "source": [
    "Define evaluation function\n",
    "\n",
    "Same can be used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mMw9wi2G4FAb"
   },
   "outputs": [],
   "source": [
    "def val_step(model, inputs, labels):\n",
    "  # get inputs and labels from given batch\n",
    "  with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # calculate the predicted class\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    loss = criterion(outputs, labels)\n",
    "    correct_pred = (predicted == labels).sum().item() # correctly classified samples of the current batch\n",
    "  return correct_pred, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVyYxxZd4vIz"
   },
   "source": [
    "Main training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bDLwIDDe4t4V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda:0\n",
      "epoch 0, step = 01000, running loss = 2.0423\n",
      "epoch 0, step = 02000, running loss = 1.8192\n",
      "epoch 0, step = 03000, running loss = 1.7383\n",
      "epoch 0, step = 04000, running loss = 1.6196\n",
      "epoch 0, step = 05000, running loss = 1.5536\n",
      "epoch 0, step = 06000, running loss = 1.4446\n",
      "epoch 0, step = 07000, running loss = 1.4143\n",
      "epoch 0, step = 08000, running loss = 1.3532\n",
      "epoch 0, step = 09000, running loss = 1.3220\n",
      "epoch 0, step = 10000, running loss = 1.2883\n",
      "val accuracy: 55.18, avg loss = 1.242\n",
      "epoch 1, step = 01000, running loss = 1.2211\n",
      "epoch 1, step = 02000, running loss = 1.2139\n",
      "epoch 1, step = 03000, running loss = 1.1665\n",
      "epoch 1, step = 04000, running loss = 1.1507\n",
      "epoch 1, step = 05000, running loss = 1.1252\n",
      "epoch 1, step = 06000, running loss = 1.1162\n",
      "epoch 1, step = 07000, running loss = 1.0888\n",
      "epoch 1, step = 08000, running loss = 1.0730\n",
      "epoch 1, step = 09000, running loss = 1.0498\n",
      "epoch 1, step = 10000, running loss = 0.9914\n",
      "val accuracy: 63.93, avg loss = 1.015\n",
      "epoch 2, step = 01000, running loss = 0.9654\n",
      "epoch 2, step = 02000, running loss = 0.9626\n",
      "epoch 2, step = 03000, running loss = 0.9972\n",
      "epoch 2, step = 04000, running loss = 0.9721\n",
      "epoch 2, step = 05000, running loss = 0.9227\n",
      "epoch 2, step = 06000, running loss = 0.8999\n",
      "epoch 2, step = 07000, running loss = 0.8584\n",
      "epoch 2, step = 08000, running loss = 0.8868\n",
      "epoch 2, step = 09000, running loss = 0.8677\n",
      "epoch 2, step = 10000, running loss = 0.8321\n",
      "val accuracy: 69.43, avg loss = 0.883\n",
      "epoch 3, step = 01000, running loss = 0.8455\n",
      "epoch 3, step = 02000, running loss = 0.8129\n",
      "epoch 3, step = 03000, running loss = 0.7833\n",
      "epoch 3, step = 04000, running loss = 0.7999\n",
      "epoch 3, step = 05000, running loss = 0.8189\n",
      "epoch 3, step = 06000, running loss = 0.8169\n",
      "epoch 3, step = 07000, running loss = 0.7702\n",
      "epoch 3, step = 08000, running loss = 0.7753\n",
      "epoch 3, step = 09000, running loss = 0.7660\n",
      "epoch 3, step = 10000, running loss = 0.7362\n",
      "val accuracy: 74.29, avg loss = 0.741\n",
      "epoch 4, step = 01000, running loss = 0.7536\n",
      "epoch 4, step = 02000, running loss = 0.7010\n",
      "epoch 4, step = 03000, running loss = 0.7328\n",
      "epoch 4, step = 04000, running loss = 0.7214\n",
      "epoch 4, step = 05000, running loss = 0.7160\n",
      "epoch 4, step = 06000, running loss = 0.6845\n",
      "epoch 4, step = 07000, running loss = 0.7240\n",
      "epoch 4, step = 08000, running loss = 0.6864\n",
      "epoch 4, step = 09000, running loss = 0.7036\n",
      "epoch 4, step = 10000, running loss = 0.6653\n",
      "val accuracy: 73.02, avg loss = 0.773\n",
      "epoch 5, step = 01000, running loss = 0.6506\n",
      "epoch 5, step = 02000, running loss = 0.6609\n",
      "epoch 5, step = 03000, running loss = 0.6708\n",
      "epoch 5, step = 04000, running loss = 0.6461\n",
      "epoch 5, step = 05000, running loss = 0.6523\n",
      "epoch 5, step = 06000, running loss = 0.6341\n",
      "epoch 5, step = 07000, running loss = 0.6278\n",
      "epoch 5, step = 08000, running loss = 0.6294\n",
      "epoch 5, step = 09000, running loss = 0.6564\n",
      "epoch 5, step = 10000, running loss = 0.6515\n",
      "val accuracy: 77.26, avg loss = 0.669\n",
      "epoch 6, step = 01000, running loss = 0.6140\n",
      "epoch 6, step = 02000, running loss = 0.6203\n",
      "epoch 6, step = 03000, running loss = 0.5922\n",
      "epoch 6, step = 04000, running loss = 0.5937\n",
      "epoch 6, step = 05000, running loss = 0.5827\n",
      "epoch 6, step = 06000, running loss = 0.6179\n",
      "epoch 6, step = 07000, running loss = 0.6151\n",
      "epoch 6, step = 08000, running loss = 0.5708\n",
      "epoch 6, step = 09000, running loss = 0.5897\n",
      "epoch 6, step = 10000, running loss = 0.5629\n",
      "val accuracy: 79.08, avg loss = 0.605\n",
      "epoch 7, step = 01000, running loss = 0.5661\n",
      "epoch 7, step = 02000, running loss = 0.5718\n",
      "epoch 7, step = 03000, running loss = 0.5685\n",
      "epoch 7, step = 04000, running loss = 0.5612\n",
      "epoch 7, step = 05000, running loss = 0.5527\n",
      "epoch 7, step = 06000, running loss = 0.5825\n",
      "epoch 7, step = 07000, running loss = 0.5577\n",
      "epoch 7, step = 08000, running loss = 0.5560\n",
      "epoch 7, step = 09000, running loss = 0.5428\n",
      "epoch 7, step = 10000, running loss = 0.5490\n",
      "val accuracy: 80.55, avg loss = 0.565\n",
      "epoch 8, step = 01000, running loss = 0.5234\n",
      "epoch 8, step = 02000, running loss = 0.5266\n",
      "epoch 8, step = 03000, running loss = 0.5334\n",
      "epoch 8, step = 04000, running loss = 0.5252\n",
      "epoch 8, step = 05000, running loss = 0.5125\n",
      "epoch 8, step = 06000, running loss = 0.5185\n",
      "epoch 8, step = 07000, running loss = 0.5361\n",
      "epoch 8, step = 08000, running loss = 0.5418\n",
      "epoch 8, step = 09000, running loss = 0.5070\n",
      "epoch 8, step = 10000, running loss = 0.5271\n",
      "val accuracy: 81.61, avg loss = 0.537\n",
      "epoch 9, step = 01000, running loss = 0.5031\n",
      "epoch 9, step = 02000, running loss = 0.4923\n",
      "epoch 9, step = 03000, running loss = 0.4901\n",
      "epoch 9, step = 04000, running loss = 0.4788\n",
      "epoch 9, step = 05000, running loss = 0.5138\n",
      "epoch 9, step = 06000, running loss = 0.4947\n",
      "epoch 9, step = 07000, running loss = 0.4777\n",
      "epoch 9, step = 08000, running loss = 0.5057\n",
      "epoch 9, step = 09000, running loss = 0.5104\n",
      "epoch 9, step = 10000, running loss = 0.5061\n",
      "val accuracy: 82.22, avg loss = 0.511\n",
      "epoch 10, step = 01000, running loss = 0.4539\n",
      "epoch 10, step = 02000, running loss = 0.4793\n",
      "epoch 10, step = 03000, running loss = 0.4687\n",
      "epoch 10, step = 04000, running loss = 0.4733\n",
      "epoch 10, step = 05000, running loss = 0.4661\n",
      "epoch 10, step = 06000, running loss = 0.4718\n",
      "epoch 10, step = 07000, running loss = 0.4888\n",
      "epoch 10, step = 08000, running loss = 0.4377\n",
      "epoch 10, step = 09000, running loss = 0.4815\n",
      "epoch 10, step = 10000, running loss = 0.4695\n",
      "val accuracy: 82.76, avg loss = 0.498\n",
      "epoch 11, step = 01000, running loss = 0.4343\n",
      "epoch 11, step = 02000, running loss = 0.4492\n",
      "epoch 11, step = 03000, running loss = 0.4412\n",
      "epoch 11, step = 04000, running loss = 0.4501\n",
      "epoch 11, step = 05000, running loss = 0.4480\n",
      "epoch 11, step = 06000, running loss = 0.4542\n",
      "epoch 11, step = 07000, running loss = 0.4425\n",
      "epoch 11, step = 08000, running loss = 0.4703\n",
      "epoch 11, step = 09000, running loss = 0.4844\n",
      "epoch 11, step = 10000, running loss = 0.4604\n",
      "val accuracy: 82.40, avg loss = 0.519\n",
      "epoch 12, step = 01000, running loss = 0.4143\n",
      "epoch 12, step = 02000, running loss = 0.4260\n",
      "epoch 12, step = 03000, running loss = 0.4211\n",
      "epoch 12, step = 04000, running loss = 0.4372\n",
      "epoch 12, step = 05000, running loss = 0.4300\n",
      "epoch 12, step = 06000, running loss = 0.4420\n",
      "epoch 12, step = 07000, running loss = 0.4396\n",
      "epoch 12, step = 08000, running loss = 0.4384\n",
      "epoch 12, step = 09000, running loss = 0.4423\n",
      "epoch 12, step = 10000, running loss = 0.4392\n",
      "val accuracy: 82.32, avg loss = 0.507\n",
      "epoch 13, step = 01000, running loss = 0.4036\n",
      "epoch 13, step = 02000, running loss = 0.4062\n",
      "epoch 13, step = 03000, running loss = 0.4112\n",
      "epoch 13, step = 04000, running loss = 0.4181\n",
      "epoch 13, step = 05000, running loss = 0.4422\n",
      "epoch 13, step = 06000, running loss = 0.3908\n",
      "epoch 13, step = 07000, running loss = 0.4168\n",
      "epoch 13, step = 08000, running loss = 0.4164\n",
      "epoch 13, step = 09000, running loss = 0.4047\n",
      "epoch 13, step = 10000, running loss = 0.4213\n",
      "val accuracy: 84.12, avg loss = 0.463\n",
      "epoch 14, step = 01000, running loss = 0.3881\n",
      "epoch 14, step = 02000, running loss = 0.4078\n",
      "epoch 14, step = 03000, running loss = 0.3994\n",
      "epoch 14, step = 04000, running loss = 0.4135\n",
      "epoch 14, step = 05000, running loss = 0.3977\n",
      "epoch 14, step = 06000, running loss = 0.4020\n",
      "epoch 14, step = 07000, running loss = 0.4063\n",
      "epoch 14, step = 08000, running loss = 0.4141\n",
      "epoch 14, step = 09000, running loss = 0.3887\n",
      "epoch 14, step = 10000, running loss = 0.3804\n",
      "val accuracy: 83.42, avg loss = 0.472\n",
      "epoch 15, step = 01000, running loss = 0.3687\n",
      "epoch 15, step = 02000, running loss = 0.3591\n",
      "epoch 15, step = 03000, running loss = 0.3928\n",
      "epoch 15, step = 04000, running loss = 0.3786\n",
      "epoch 15, step = 05000, running loss = 0.3975\n",
      "epoch 15, step = 06000, running loss = 0.3985\n",
      "epoch 15, step = 07000, running loss = 0.3792\n",
      "epoch 15, step = 08000, running loss = 0.3867\n",
      "epoch 15, step = 09000, running loss = 0.4097\n",
      "epoch 15, step = 10000, running loss = 0.3853\n",
      "val accuracy: 84.62, avg loss = 0.450\n",
      "epoch 16, step = 01000, running loss = 0.3664\n",
      "epoch 16, step = 02000, running loss = 0.3987\n",
      "epoch 16, step = 03000, running loss = 0.3602\n",
      "epoch 16, step = 04000, running loss = 0.3555\n",
      "epoch 16, step = 05000, running loss = 0.3617\n",
      "epoch 16, step = 06000, running loss = 0.3685\n",
      "epoch 16, step = 07000, running loss = 0.3758\n",
      "epoch 16, step = 08000, running loss = 0.3738\n",
      "epoch 16, step = 09000, running loss = 0.3993\n",
      "epoch 16, step = 10000, running loss = 0.3959\n",
      "val accuracy: 84.80, avg loss = 0.447\n",
      "epoch 17, step = 01000, running loss = 0.3599\n",
      "epoch 17, step = 02000, running loss = 0.3514\n",
      "epoch 17, step = 03000, running loss = 0.3580\n",
      "epoch 17, step = 04000, running loss = 0.3583\n",
      "epoch 17, step = 05000, running loss = 0.3488\n",
      "epoch 17, step = 06000, running loss = 0.3590\n",
      "epoch 17, step = 07000, running loss = 0.3732\n",
      "epoch 17, step = 08000, running loss = 0.3672\n",
      "epoch 17, step = 09000, running loss = 0.3668\n",
      "epoch 17, step = 10000, running loss = 0.3865\n",
      "val accuracy: 84.82, avg loss = 0.449\n",
      "epoch 18, step = 01000, running loss = 0.3335\n",
      "epoch 18, step = 02000, running loss = 0.3333\n",
      "epoch 18, step = 03000, running loss = 0.3714\n",
      "epoch 18, step = 04000, running loss = 0.3490\n",
      "epoch 18, step = 05000, running loss = 0.3619\n",
      "epoch 18, step = 06000, running loss = 0.3696\n",
      "epoch 18, step = 07000, running loss = 0.3459\n",
      "epoch 18, step = 08000, running loss = 0.3553\n",
      "epoch 18, step = 09000, running loss = 0.3597\n",
      "epoch 18, step = 10000, running loss = 0.3670\n",
      "val accuracy: 85.40, avg loss = 0.427\n",
      "epoch 19, step = 01000, running loss = 0.3377\n",
      "epoch 19, step = 02000, running loss = 0.3252\n",
      "epoch 19, step = 03000, running loss = 0.3361\n",
      "epoch 19, step = 04000, running loss = 0.3364\n",
      "epoch 19, step = 05000, running loss = 0.3501\n",
      "epoch 19, step = 06000, running loss = 0.3325\n",
      "epoch 19, step = 07000, running loss = 0.3566\n",
      "epoch 19, step = 08000, running loss = 0.3433\n",
      "epoch 19, step = 09000, running loss = 0.3539\n",
      "epoch 19, step = 10000, running loss = 0.3645\n",
      "val accuracy: 85.51, avg loss = 0.433\n",
      "epoch 20, step = 01000, running loss = 0.3303\n",
      "epoch 20, step = 02000, running loss = 0.3388\n",
      "epoch 20, step = 03000, running loss = 0.3223\n",
      "epoch 20, step = 04000, running loss = 0.3323\n",
      "epoch 20, step = 05000, running loss = 0.3251\n",
      "epoch 20, step = 06000, running loss = 0.3480\n",
      "epoch 20, step = 07000, running loss = 0.3398\n",
      "epoch 20, step = 08000, running loss = 0.3278\n",
      "epoch 20, step = 09000, running loss = 0.3398\n",
      "epoch 20, step = 10000, running loss = 0.3276\n",
      "val accuracy: 84.98, avg loss = 0.436\n",
      "epoch 21, step = 01000, running loss = 0.3216\n",
      "epoch 21, step = 02000, running loss = 0.3187\n",
      "epoch 21, step = 03000, running loss = 0.3337\n",
      "epoch 21, step = 04000, running loss = 0.3274\n",
      "epoch 21, step = 05000, running loss = 0.3304\n",
      "epoch 21, step = 06000, running loss = 0.3166\n",
      "epoch 21, step = 07000, running loss = 0.3325\n",
      "epoch 21, step = 08000, running loss = 0.3070\n",
      "epoch 21, step = 09000, running loss = 0.3671\n",
      "epoch 21, step = 10000, running loss = 0.3311\n",
      "val accuracy: 85.90, avg loss = 0.414\n",
      "epoch 22, step = 01000, running loss = 0.3108\n",
      "epoch 22, step = 02000, running loss = 0.3144\n",
      "epoch 22, step = 03000, running loss = 0.3307\n",
      "epoch 22, step = 04000, running loss = 0.2844\n",
      "epoch 22, step = 05000, running loss = 0.3483\n",
      "epoch 22, step = 06000, running loss = 0.3465\n",
      "epoch 22, step = 07000, running loss = 0.3148\n",
      "epoch 22, step = 08000, running loss = 0.3018\n",
      "epoch 22, step = 09000, running loss = 0.3255\n",
      "epoch 22, step = 10000, running loss = 0.3425\n",
      "val accuracy: 85.92, avg loss = 0.405\n",
      "epoch 23, step = 01000, running loss = 0.2947\n",
      "epoch 23, step = 02000, running loss = 0.3095\n",
      "epoch 23, step = 03000, running loss = 0.3089\n",
      "epoch 23, step = 04000, running loss = 0.3096\n",
      "epoch 23, step = 05000, running loss = 0.3193\n",
      "epoch 23, step = 06000, running loss = 0.3325\n",
      "epoch 23, step = 07000, running loss = 0.3490\n",
      "epoch 23, step = 08000, running loss = 0.3039\n",
      "epoch 23, step = 09000, running loss = 0.3321\n",
      "epoch 23, step = 10000, running loss = 0.3338\n",
      "val accuracy: 86.47, avg loss = 0.400\n",
      "epoch 24, step = 01000, running loss = 0.3188\n",
      "epoch 24, step = 02000, running loss = 0.2969\n",
      "epoch 24, step = 03000, running loss = 0.3065\n",
      "epoch 24, step = 04000, running loss = 0.2927\n",
      "epoch 24, step = 05000, running loss = 0.3204\n",
      "epoch 24, step = 06000, running loss = 0.3231\n",
      "epoch 24, step = 07000, running loss = 0.3357\n",
      "epoch 24, step = 08000, running loss = 0.3130\n",
      "epoch 24, step = 09000, running loss = 0.3156\n",
      "epoch 24, step = 10000, running loss = 0.3230\n",
      "val accuracy: 85.98, avg loss = 0.421\n",
      "epoch 25, step = 01000, running loss = 0.2812\n",
      "epoch 25, step = 02000, running loss = 0.2971\n",
      "epoch 25, step = 03000, running loss = 0.2991\n",
      "epoch 25, step = 04000, running loss = 0.3158\n",
      "epoch 25, step = 05000, running loss = 0.3113\n",
      "epoch 25, step = 06000, running loss = 0.2991\n",
      "epoch 25, step = 07000, running loss = 0.3110\n",
      "epoch 25, step = 08000, running loss = 0.3295\n",
      "epoch 25, step = 09000, running loss = 0.3102\n",
      "epoch 25, step = 10000, running loss = 0.3201\n",
      "val accuracy: 85.55, avg loss = 0.425\n",
      "epoch 26, step = 01000, running loss = 0.2846\n",
      "epoch 26, step = 02000, running loss = 0.2876\n",
      "epoch 26, step = 03000, running loss = 0.2874\n",
      "epoch 26, step = 04000, running loss = 0.3069\n",
      "epoch 26, step = 05000, running loss = 0.3395\n",
      "epoch 26, step = 06000, running loss = 0.3079\n",
      "epoch 26, step = 07000, running loss = 0.3094\n",
      "epoch 26, step = 08000, running loss = 0.3229\n",
      "epoch 26, step = 09000, running loss = 0.3181\n",
      "epoch 26, step = 10000, running loss = 0.2960\n",
      "val accuracy: 85.47, avg loss = 0.429\n",
      "epoch 27, step = 01000, running loss = 0.2928\n",
      "epoch 27, step = 02000, running loss = 0.2927\n",
      "epoch 27, step = 03000, running loss = 0.2905\n",
      "epoch 27, step = 04000, running loss = 0.2707\n",
      "epoch 27, step = 05000, running loss = 0.3022\n",
      "epoch 27, step = 06000, running loss = 0.3070\n",
      "epoch 27, step = 07000, running loss = 0.3261\n",
      "epoch 27, step = 08000, running loss = 0.3007\n",
      "epoch 27, step = 09000, running loss = 0.3192\n",
      "epoch 27, step = 10000, running loss = 0.3268\n",
      "val accuracy: 85.99, avg loss = 0.412\n",
      "epoch 28, step = 01000, running loss = 0.2622\n",
      "epoch 28, step = 02000, running loss = 0.2961\n",
      "epoch 28, step = 03000, running loss = 0.2855\n",
      "epoch 28, step = 04000, running loss = 0.2891\n",
      "epoch 28, step = 05000, running loss = 0.2944\n",
      "epoch 28, step = 06000, running loss = 0.2887\n",
      "epoch 28, step = 07000, running loss = 0.2987\n",
      "epoch 28, step = 08000, running loss = 0.2952\n",
      "epoch 28, step = 09000, running loss = 0.3165\n",
      "epoch 28, step = 10000, running loss = 0.3074\n",
      "val accuracy: 86.31, avg loss = 0.402\n",
      "epoch 29, step = 01000, running loss = 0.2805\n",
      "epoch 29, step = 02000, running loss = 0.2669\n",
      "epoch 29, step = 03000, running loss = 0.2967\n",
      "epoch 29, step = 04000, running loss = 0.3035\n",
      "epoch 29, step = 05000, running loss = 0.2937\n",
      "epoch 29, step = 06000, running loss = 0.2914\n",
      "epoch 29, step = 07000, running loss = 0.2810\n",
      "epoch 29, step = 08000, running loss = 0.3051\n",
      "epoch 29, step = 09000, running loss = 0.2855\n",
      "epoch 29, step = 10000, running loss = 0.2838\n",
      "val accuracy: 86.69, avg loss = 0.391\n",
      "epoch 30, step = 01000, running loss = 0.2503\n",
      "epoch 30, step = 02000, running loss = 0.2877\n",
      "epoch 30, step = 03000, running loss = 0.2844\n",
      "epoch 30, step = 04000, running loss = 0.2743\n",
      "epoch 30, step = 05000, running loss = 0.2858\n",
      "epoch 30, step = 06000, running loss = 0.3166\n",
      "epoch 30, step = 07000, running loss = 0.2801\n",
      "epoch 30, step = 08000, running loss = 0.2819\n",
      "epoch 30, step = 09000, running loss = 0.3128\n",
      "epoch 30, step = 10000, running loss = 0.3213\n",
      "val accuracy: 85.97, avg loss = 0.404\n",
      "epoch 31, step = 01000, running loss = 0.2653\n",
      "epoch 31, step = 02000, running loss = 0.2771\n",
      "epoch 31, step = 03000, running loss = 0.2721\n",
      "epoch 31, step = 04000, running loss = 0.2774\n",
      "epoch 31, step = 05000, running loss = 0.2577\n",
      "epoch 31, step = 06000, running loss = 0.2702\n",
      "epoch 31, step = 07000, running loss = 0.2728\n",
      "epoch 31, step = 08000, running loss = 0.3140\n",
      "epoch 31, step = 09000, running loss = 0.3035\n",
      "epoch 31, step = 10000, running loss = 0.3122\n",
      "val accuracy: 86.19, avg loss = 0.400\n",
      "epoch 32, step = 01000, running loss = 0.2681\n",
      "epoch 32, step = 02000, running loss = 0.2746\n",
      "epoch 32, step = 03000, running loss = 0.2649\n",
      "epoch 32, step = 04000, running loss = 0.2803\n",
      "epoch 32, step = 05000, running loss = 0.2914\n",
      "epoch 32, step = 06000, running loss = 0.2926\n",
      "epoch 32, step = 07000, running loss = 0.2911\n",
      "epoch 32, step = 08000, running loss = 0.2956\n",
      "epoch 32, step = 09000, running loss = 0.2784\n",
      "epoch 32, step = 10000, running loss = 0.2935\n",
      "val accuracy: 86.74, avg loss = 0.391\n",
      "epoch 33, step = 01000, running loss = 0.2632\n",
      "epoch 33, step = 02000, running loss = 0.2575\n",
      "epoch 33, step = 03000, running loss = 0.2673\n",
      "epoch 33, step = 04000, running loss = 0.2484\n",
      "epoch 33, step = 05000, running loss = 0.2818\n",
      "epoch 33, step = 06000, running loss = 0.2882\n",
      "epoch 33, step = 07000, running loss = 0.2606\n",
      "epoch 33, step = 08000, running loss = 0.2829\n",
      "epoch 33, step = 09000, running loss = 0.3001\n",
      "epoch 33, step = 10000, running loss = 0.3082\n",
      "val accuracy: 86.79, avg loss = 0.389\n",
      "epoch 34, step = 01000, running loss = 0.2679\n",
      "epoch 34, step = 02000, running loss = 0.2723\n",
      "epoch 34, step = 03000, running loss = 0.2589\n",
      "epoch 34, step = 04000, running loss = 0.2611\n",
      "epoch 34, step = 05000, running loss = 0.2836\n",
      "epoch 34, step = 06000, running loss = 0.2876\n",
      "epoch 34, step = 07000, running loss = 0.2713\n",
      "epoch 34, step = 08000, running loss = 0.2769\n",
      "epoch 34, step = 09000, running loss = 0.2833\n",
      "epoch 34, step = 10000, running loss = 0.2833\n",
      "val accuracy: 86.24, avg loss = 0.409\n",
      "epoch 35, step = 01000, running loss = 0.2720\n",
      "epoch 35, step = 02000, running loss = 0.2603\n",
      "epoch 35, step = 03000, running loss = 0.2662\n",
      "epoch 35, step = 04000, running loss = 0.2546\n",
      "epoch 35, step = 05000, running loss = 0.2867\n",
      "epoch 35, step = 06000, running loss = 0.2901\n",
      "epoch 35, step = 07000, running loss = 0.2890\n",
      "epoch 35, step = 08000, running loss = 0.2836\n",
      "epoch 35, step = 09000, running loss = 0.2888\n",
      "epoch 35, step = 10000, running loss = 0.2682\n",
      "val accuracy: 86.62, avg loss = 0.397\n",
      "epoch 36, step = 01000, running loss = 0.2456\n",
      "epoch 36, step = 02000, running loss = 0.2495\n",
      "epoch 36, step = 03000, running loss = 0.2694\n",
      "epoch 36, step = 04000, running loss = 0.2674\n",
      "epoch 36, step = 05000, running loss = 0.2624\n",
      "epoch 36, step = 06000, running loss = 0.2718\n",
      "epoch 36, step = 07000, running loss = 0.2898\n",
      "epoch 36, step = 08000, running loss = 0.2841\n",
      "epoch 36, step = 09000, running loss = 0.2716\n",
      "epoch 36, step = 10000, running loss = 0.2593\n",
      "val accuracy: 86.72, avg loss = 0.391\n",
      "epoch 37, step = 01000, running loss = 0.2597\n",
      "epoch 37, step = 02000, running loss = 0.2688\n",
      "epoch 37, step = 03000, running loss = 0.2373\n",
      "epoch 37, step = 04000, running loss = 0.2683\n",
      "epoch 37, step = 05000, running loss = 0.2662\n",
      "epoch 37, step = 06000, running loss = 0.2775\n",
      "epoch 37, step = 07000, running loss = 0.2635\n",
      "epoch 37, step = 08000, running loss = 0.2752\n",
      "epoch 37, step = 09000, running loss = 0.2846\n",
      "epoch 37, step = 10000, running loss = 0.3052\n",
      "val accuracy: 86.83, avg loss = 0.393\n",
      "epoch 38, step = 01000, running loss = 0.2357\n",
      "epoch 38, step = 02000, running loss = 0.2414\n",
      "epoch 38, step = 03000, running loss = 0.2463\n",
      "epoch 38, step = 04000, running loss = 0.2912\n",
      "epoch 38, step = 05000, running loss = 0.2622\n",
      "epoch 38, step = 06000, running loss = 0.2778\n",
      "epoch 38, step = 07000, running loss = 0.2807\n",
      "epoch 38, step = 08000, running loss = 0.2708\n",
      "epoch 38, step = 09000, running loss = 0.2647\n",
      "epoch 38, step = 10000, running loss = 0.2708\n",
      "val accuracy: 86.85, avg loss = 0.378\n",
      "epoch 39, step = 01000, running loss = 0.2363\n",
      "epoch 39, step = 02000, running loss = 0.2749\n",
      "epoch 39, step = 03000, running loss = 0.2440\n",
      "epoch 39, step = 04000, running loss = 0.2463\n",
      "epoch 39, step = 05000, running loss = 0.2554\n",
      "epoch 39, step = 06000, running loss = 0.2587\n",
      "epoch 39, step = 07000, running loss = 0.2693\n",
      "epoch 39, step = 08000, running loss = 0.2817\n",
      "epoch 39, step = 09000, running loss = 0.2795\n",
      "epoch 39, step = 10000, running loss = 0.2844\n",
      "val accuracy: 86.90, avg loss = 0.385\n",
      "epoch 40, step = 01000, running loss = 0.2288\n",
      "epoch 40, step = 02000, running loss = 0.2408\n",
      "epoch 40, step = 03000, running loss = 0.2472\n",
      "epoch 40, step = 04000, running loss = 0.2472\n",
      "epoch 40, step = 05000, running loss = 0.2841\n",
      "epoch 40, step = 06000, running loss = 0.2808\n",
      "epoch 40, step = 07000, running loss = 0.2489\n",
      "epoch 40, step = 08000, running loss = 0.2562\n",
      "epoch 40, step = 09000, running loss = 0.2633\n",
      "epoch 40, step = 10000, running loss = 0.2845\n",
      "val accuracy: 87.05, avg loss = 0.369\n",
      "epoch 41, step = 01000, running loss = 0.2439\n",
      "epoch 41, step = 02000, running loss = 0.2628\n",
      "epoch 41, step = 03000, running loss = 0.2474\n",
      "epoch 41, step = 04000, running loss = 0.2603\n",
      "epoch 41, step = 05000, running loss = 0.2702\n",
      "epoch 41, step = 06000, running loss = 0.2706\n",
      "epoch 41, step = 07000, running loss = 0.2570\n",
      "epoch 41, step = 08000, running loss = 0.2608\n",
      "epoch 41, step = 09000, running loss = 0.2621\n",
      "epoch 41, step = 10000, running loss = 0.2837\n",
      "val accuracy: 86.40, avg loss = 0.401\n",
      "epoch 42, step = 01000, running loss = 0.2448\n",
      "epoch 42, step = 02000, running loss = 0.2434\n",
      "epoch 42, step = 03000, running loss = 0.2457\n",
      "epoch 42, step = 04000, running loss = 0.2657\n",
      "epoch 42, step = 05000, running loss = 0.2391\n",
      "epoch 42, step = 06000, running loss = 0.2684\n",
      "epoch 42, step = 07000, running loss = 0.2817\n",
      "epoch 42, step = 08000, running loss = 0.2606\n",
      "epoch 42, step = 09000, running loss = 0.2849\n",
      "epoch 42, step = 10000, running loss = 0.2635\n",
      "val accuracy: 87.16, avg loss = 0.381\n",
      "epoch 43, step = 01000, running loss = 0.2478\n",
      "epoch 43, step = 02000, running loss = 0.2520\n",
      "epoch 43, step = 03000, running loss = 0.2355\n",
      "epoch 43, step = 04000, running loss = 0.2375\n",
      "epoch 43, step = 05000, running loss = 0.2597\n",
      "epoch 43, step = 06000, running loss = 0.2734\n",
      "epoch 43, step = 07000, running loss = 0.2551\n",
      "epoch 43, step = 08000, running loss = 0.2664\n",
      "epoch 43, step = 09000, running loss = 0.2518\n",
      "epoch 43, step = 10000, running loss = 0.2622\n",
      "val accuracy: 87.00, avg loss = 0.380\n",
      "epoch 44, step = 01000, running loss = 0.2368\n",
      "epoch 44, step = 02000, running loss = 0.2655\n",
      "epoch 44, step = 03000, running loss = 0.2274\n",
      "epoch 44, step = 04000, running loss = 0.2787\n",
      "epoch 44, step = 05000, running loss = 0.2337\n",
      "epoch 44, step = 06000, running loss = 0.2474\n",
      "epoch 44, step = 07000, running loss = 0.2585\n",
      "epoch 44, step = 08000, running loss = 0.2702\n",
      "epoch 44, step = 09000, running loss = 0.2849\n",
      "epoch 44, step = 10000, running loss = 0.2574\n",
      "val accuracy: 87.25, avg loss = 0.379\n",
      "epoch 45, step = 01000, running loss = 0.2436\n",
      "epoch 45, step = 02000, running loss = 0.2359\n",
      "epoch 45, step = 03000, running loss = 0.2490\n",
      "epoch 45, step = 04000, running loss = 0.2378\n",
      "epoch 45, step = 05000, running loss = 0.2612\n",
      "epoch 45, step = 06000, running loss = 0.2528\n",
      "epoch 45, step = 07000, running loss = 0.2382\n",
      "epoch 45, step = 08000, running loss = 0.2584\n",
      "epoch 45, step = 09000, running loss = 0.2840\n",
      "epoch 45, step = 10000, running loss = 0.2631\n",
      "val accuracy: 86.50, avg loss = 0.401\n",
      "epoch 46, step = 01000, running loss = 0.2176\n",
      "epoch 46, step = 02000, running loss = 0.2295\n",
      "epoch 46, step = 03000, running loss = 0.2453\n",
      "epoch 46, step = 04000, running loss = 0.2481\n",
      "epoch 46, step = 05000, running loss = 0.2376\n",
      "epoch 46, step = 06000, running loss = 0.2634\n",
      "epoch 46, step = 07000, running loss = 0.2575\n",
      "epoch 46, step = 08000, running loss = 0.2455\n",
      "epoch 46, step = 09000, running loss = 0.2470\n",
      "epoch 46, step = 10000, running loss = 0.2996\n",
      "val accuracy: 87.21, avg loss = 0.391\n",
      "epoch 47, step = 01000, running loss = 0.2289\n",
      "epoch 47, step = 02000, running loss = 0.2438\n",
      "epoch 47, step = 03000, running loss = 0.2251\n",
      "epoch 47, step = 04000, running loss = 0.2620\n",
      "epoch 47, step = 05000, running loss = 0.2561\n",
      "epoch 47, step = 06000, running loss = 0.2377\n",
      "epoch 47, step = 07000, running loss = 0.2565\n",
      "epoch 47, step = 08000, running loss = 0.2456\n",
      "epoch 47, step = 09000, running loss = 0.2683\n",
      "epoch 47, step = 10000, running loss = 0.2508\n",
      "val accuracy: 86.28, avg loss = 0.406\n",
      "epoch 48, step = 01000, running loss = 0.2260\n",
      "epoch 48, step = 02000, running loss = 0.2452\n",
      "epoch 48, step = 03000, running loss = 0.2352\n",
      "epoch 48, step = 04000, running loss = 0.2403\n",
      "epoch 48, step = 05000, running loss = 0.2594\n",
      "epoch 48, step = 06000, running loss = 0.2330\n",
      "epoch 48, step = 07000, running loss = 0.2450\n",
      "epoch 48, step = 08000, running loss = 0.2416\n",
      "epoch 48, step = 09000, running loss = 0.2565\n",
      "epoch 48, step = 10000, running loss = 0.2567\n",
      "val accuracy: 87.48, avg loss = 0.377\n",
      "epoch 49, step = 01000, running loss = 0.2415\n",
      "epoch 49, step = 02000, running loss = 0.2353\n",
      "epoch 49, step = 03000, running loss = 0.2463\n",
      "epoch 49, step = 04000, running loss = 0.2102\n",
      "epoch 49, step = 05000, running loss = 0.2468\n",
      "epoch 49, step = 06000, running loss = 0.2615\n",
      "epoch 49, step = 07000, running loss = 0.2461\n",
      "epoch 49, step = 08000, running loss = 0.2534\n",
      "epoch 49, step = 09000, running loss = 0.2680\n",
      "epoch 49, step = 10000, running loss = 0.2659\n",
      "val accuracy: 87.34, avg loss = 0.375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 50 # change this to a larger number to train the final network\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using device: \", device)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "  running_loss = 0\n",
    "  for j, batch in enumerate(trainloader):\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # training step\n",
    "    loss = train_step(model, inputs, labels)\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # print some statistics\n",
    "    if (j+1) % 1000 == 0 :\n",
    "      print(\"epoch {}, step = {}, running loss = {:.4f}\".format(i, str(j+1).zfill(5), running_loss / 1000))\n",
    "      running_loss = 0\n",
    "\n",
    "\n",
    "\n",
    "  # validation at the end of each epoch\n",
    "  total_correct_pred = 0\n",
    "  val_loss = []\n",
    "  for _, batch in enumerate(valloader):\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    curr_correct_pred, curr_loss = val_step(model, inputs, labels)\n",
    "\n",
    "    # keep track of corrected samples and loss\n",
    "    total_correct_pred += curr_correct_pred\n",
    "    val_loss.append(curr_loss.item())\n",
    "\n",
    "  val_loss = torch.Tensor(val_loss).mean()\n",
    "  acc = total_correct_pred / len(valset)\n",
    "  print(\"val accuracy: {:.2f}, avg loss = {:.3f}\".format(100*acc, val_loss))\n",
    "  val_acc_log.append(acc * 100)\n",
    "  val_loss_log.append(val_loss.item())\n",
    "\n",
    "  # save the checkpoint\n",
    "  torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'epoch_{}_val_acc_{}.pt'.format(i, 100*acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NcV8B83ab6Tk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(val_loss_log)\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_ylabel('loss')\n",
    "ax[0].set_title('validation loss')\n",
    "\n",
    "\n",
    "ax[1].plot(val_acc_log)\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_ylabel('accuracy')\n",
    "ax[1].set_title('validation accuracy')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aomKGsVO7XY2"
   },
   "source": [
    "Testing\n",
    "\n",
    "The other things to do is to calculate the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) to see the accuracy of individual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SwB2EmvW7Yty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 86.85%\n"
     ]
    }
   ],
   "source": [
    "from os import access\n",
    "total_correct_pred = 0\n",
    "\n",
    "for i, batch in enumerate(testloader):\n",
    "  inputs, labels = batch\n",
    "  inputs = inputs.to(device)\n",
    "  labels = labels.to(device)\n",
    "\n",
    "  curr_correct_pred, _ = val_step(model, inputs, labels)\n",
    "\n",
    "  # adding up correctly predicted samples\n",
    "  total_correct_pred += curr_correct_pred\n",
    "\n",
    "# total accuracy\n",
    "acc = total_correct_pred / len(testloader.dataset)\n",
    "print(\"testing accuracy: {:.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 87 %\n",
      "Accuracy of   car : 95 %\n",
      "Accuracy of  bird : 78 %\n",
      "Accuracy of   cat : 80 %\n",
      "Accuracy of  deer : 86 %\n",
      "Accuracy of   dog : 82 %\n",
      "Accuracy of  frog : 88 %\n",
      "Accuracy of horse : 90 %\n",
      "Accuracy of  ship : 89 %\n",
      "Accuracy of truck : 88 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in testloader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
